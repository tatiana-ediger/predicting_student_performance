{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads data\n",
    "features = pd.read_csv(\"data/features.csv\")\n",
    "target = pd.read_csv(\"data/target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins target values\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode = \"onehot-dense\", strategy = \"quantile\")\n",
    "\n",
    "target_discretized = discretizer.fit_transform(target[\"G3\"].values.reshape(-1, 1))\n",
    "target_new = []\n",
    "for row in target_discretized:\n",
    "    target_new.append(list(row).index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [0] * 21\n",
    "for datum in target[\"G3\"].values:\n",
    "    counts[datum] += 1\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[230, 153, 367, 294]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "counts = [0, 0, 0, 0]\n",
    "for datum in target_new:\n",
    "    counts[datum] += 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into training, testing sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(features, target, test_size = 0.3,random_state = 1001)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = 0.5, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets final grade for target\n",
    "t_train = y_train[\"G3\"]\n",
    "t_val = y_val[\"G3\"]\n",
    "t_test = y_test[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 100\nR-squared value for training set:  0.31458176149234485\nR-squared value for testing set:  0.2651854418480488\n"
    }
   ],
   "source": [
    "# Imports Ridge and accuracy metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(Ridge(alpha = param).fit(X=X_train, y=t_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(r2_score(t_val, model.predict(X_val)))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "ridge_train_score = r2_score(t_train, best_model.predict(X_train))\n",
    "ridge_val_score =  r2_score(t_val, best_model.predict(X_val))\n",
    "ridge_test_score = r2_score(t_test, best_model.predict(X_test))\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"R-squared value for training set: \", r2_score(t_train, best_model.predict(X_train)))\n",
    "print(\"R-squared value for testing set: \", r2_score(t_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 0.01\nR-squared value for training set:  0.3446902144741497\nR-squared value for testing set:  0.26472075923764216\n"
    }
   ],
   "source": [
    "# Imports Lasso and accuracy metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(Lasso(alpha = param).fit(X=X_train, y=t_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(r2_score(t_val, model.predict(X_val)))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "# Performs Lasso Regression\n",
    "lasso_train_score = r2_score(t_train, best_model.predict(X_train))\n",
    "lasso_val_score =  r2_score(t_val, best_model.predict(X_val))\n",
    "lasso_test_score = r2_score(t_test, best_model.predict(X_test))\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"R-squared value for training set: \", r2_score(t_train, best_model.predict(X_train)))\n",
    "print(\"R-squared value for testing set: \", r2_score(t_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(data = {\"Ridge\": [ridge_train_score, ridge_val_score, ridge_test_score], \"Lasso\":[lasso_train_score, lasso_val_score, lasso_test_score]})\n",
    "summary.index = [\"R^2 on training\", \"R^2 on validation\", \"R^2 on testing\"]\n",
    "summary.T.to_html(\"regression.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into training, valdation, testing sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(features, target_new, test_size = 0.3,random_state = 1001)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = 0.5, random_state = 1001)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 0.001\nPrediction accuracy on the train data: 48.22%\nPrediction accuracy on the test data: 36.94%\n"
    }
   ],
   "source": [
    "# Imports SVC and accuracy metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Recommended using kernel\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(SVC(gamma = param).fit(X=X_train, y=y_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(model.score(X_val, y_val))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "\n",
    "# Measures accuracy\n",
    "kernel_accuracy_train = best_model.score(X_train, y_train)\n",
    "kernel_accuracy_val = best_score\n",
    "kernel_accuracy_test = best_model.score(X_test, y_test)\n",
    "kernel_scores = [kernel_accuracy_train, kernel_accuracy_val, kernel_accuracy_test]\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"Prediction accuracy on the train data:\", f\"{kernel_accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{kernel_accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction accuracy on the train data: 41.10%\nPrediction accuracy on the test data: 35.67%\n"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "model = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Measures accuracy\n",
    "accuracy_train = model.score(X_train, y_train)\n",
    "accuracy_test = model.score(X_test, y_test)\n",
    "linear_scores = [accuracy_train, \"N/A\", accuracy_test]\n",
    "print(\"Prediction accuracy on the train data:\", f\"{accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 5\nPrediction accuracy on the train data: 56.58%\nPrediction accuracy on the test data: 35.03%\n"
    }
   ],
   "source": [
    "# Imports Decision Tree and accuracy metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Recommended using kernel\n",
    "param_grid = [1, 5, 10, 25, 50]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(DecisionTreeClassifier(max_depth = param).fit(X=X_train, y=y_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(model.score(X_val, y_val))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "# Performs Decision Tree Classifier\n",
    "model = DecisionTreeClassifier().fit(X=X_train, y=y_train)\n",
    "\n",
    "# Recommended using kernel -> we want to be able to model nonlinear things!\n",
    "# Want to use feature expansion to classify them\n",
    "# To choose the kernel: brute force/ try out a bunch of different ones (look at data and see if there's anything interesting you can pick up on, for example see if there's any 2 or more things that you can take the product of and it seems interesting)\n",
    "# kernel: considering n features at the same time\n",
    "\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "dt_accuracy_train = best_model.score(X_train, y_train)\n",
    "dt_accuracy_val = best_score\n",
    "dt_accuracy_test = best_model.score(X_test, y_test)\n",
    "dt_scores = [dt_accuracy_train, dt_accuracy_val, dt_accuracy_test]\n",
    "print(\"Prediction accuracy on the train data:\", f\"{dt_accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{dt_accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(data = {\"RBF Kernel SVM\": kernel_scores, \"Linear SVM\":linear_scores, \"Descision Tree\": dt_scores})\n",
    "summary.index = [\"Accuracy on training\", \"Accuracy on validation\", \"Accuracy on testing\"]\n",
    "summary.T.to_html(\"classification.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}