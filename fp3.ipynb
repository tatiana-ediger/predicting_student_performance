{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads data\n",
    "features = pd.read_csv(\"data/features.csv\")\n",
    "target = pd.read_csv(\"data/target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins target values\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode = \"onehot-dense\", strategy = \"quantile\")\n",
    "\n",
    "target_discretized = discretizer.fit_transform(target[\"G3\"].values.reshape(-1, 1))\n",
    "target_new = []\n",
    "for row in target_discretized:\n",
    "    target_new.append(list(row).index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates counts for original data\n",
    "counts = [0] * 21\n",
    "for datum in target[\"G3\"].values:\n",
    "    counts[datum] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[230, 153, 367, 294]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# calculates counts for binned data\n",
    "counts = [0, 0, 0, 0]\n",
    "for datum in target_new:\n",
    "    counts[datum] += 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into training, validation, testing sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(features, target, test_size = 0.3,random_state = 1001)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = 0.5, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets final grade for target\n",
    "t_train = y_train[\"G3\"]\n",
    "t_val = y_val[\"G3\"]\n",
    "t_test = y_test[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 100\nR-squared value for training set:  0.31458176149234485\nR-squared value for testing set:  0.2651854418480495\n"
    }
   ],
   "source": [
    "# Imports Ridge and accuracy metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Performs Hyperparameter tuning\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(Ridge(alpha = param).fit(X=X_train, y=t_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(r2_score(t_val, model.predict(X_val)))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "# Saves results\n",
    "ridge_train_score = r2_score(t_train, best_model.predict(X_train))\n",
    "ridge_val_score =  r2_score(t_val, best_model.predict(X_val))\n",
    "ridge_test_score = r2_score(t_test, best_model.predict(X_test))\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"R-squared value for training set: \", r2_score(t_train, best_model.predict(X_train)))\n",
    "print(\"R-squared value for testing set: \", r2_score(t_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 0.01\nR-squared value for training set:  0.3446902144741497\nR-squared value for testing set:  0.26472075923764227\n"
    }
   ],
   "source": [
    "# Imports Lasso and accuracy metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Performs hyperparameter tuning\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(Lasso(alpha = param).fit(X=X_train, y=t_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(r2_score(t_val, model.predict(X_val)))\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "# Saves results\n",
    "lasso_train_score = r2_score(t_train, best_model.predict(X_train))\n",
    "lasso_val_score =  r2_score(t_val, best_model.predict(X_val))\n",
    "lasso_test_score = r2_score(t_test, best_model.predict(X_test))\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"R-squared value for training set: \", r2_score(t_train, best_model.predict(X_train)))\n",
    "print(\"R-squared value for testing set: \", r2_score(t_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a table for regression results\n",
    "summary = pd.DataFrame(data = {\"Ridge\": [ridge_train_score, ridge_val_score, ridge_test_score], \"Lasso\":[lasso_train_score, lasso_val_score, lasso_test_score]})\n",
    "summary.index = [\"R^2 on training\", \"R^2 on validation\", \"R^2 on testing\"]\n",
    "summary.T.to_html(\"tables/regression.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into training, valdation, testing sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(features, target_new, test_size = 0.3,random_state = 1001)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = 0.5, random_state = 1001)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 0.001\nPrediction accuracy on the train data: 48.22%\nPrediction accuracy on the test data: 36.94%\n"
    }
   ],
   "source": [
    "# Imports SVC and accuracy metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Performs hyperparameter tuning\n",
    "param_grid = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(SVC(gamma = param).fit(X=X_train, y=y_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(model.score(X_val, y_val))\n",
    "# Saves results\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "\n",
    "# Measures accuracy\n",
    "kernel_accuracy_train = best_model.score(X_train, y_train)\n",
    "kernel_accuracy_val = best_score\n",
    "kernel_accuracy_test = best_model.score(X_test, y_test)\n",
    "kernel_scores = [kernel_accuracy_train, kernel_accuracy_val, kernel_accuracy_test]\n",
    "print(\"Best Parameter:\", best_param)\n",
    "print(\"Prediction accuracy on the train data:\", f\"{kernel_accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{kernel_accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction accuracy on the train data: 43.42%\nPrediction accuracy on the test data: 35.03%\n"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Trains model\n",
    "model = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Measures accuracy\n",
    "linear_accuracy_train = model.score(X_train, y_train)\n",
    "linear_accuracy_val = model.score(X_val, y_val)\n",
    "linear_accuracy_test = model.score(X_test, y_test)\n",
    "linear_scores = [linear_accuracy_train, linear_accuracy_val, linear_accuracy_test]\n",
    "print(\"Prediction accuracy on the train data:\", f\"{linear_accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{linear_accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best Parameter: 5\nPrediction accuracy on the train data: 56.58%\nPrediction accuracy on the test data: 35.03%\n"
    }
   ],
   "source": [
    "# Imports Decision Tree and accuracy metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Performs hyperparameter tuning\n",
    "param_grid = [1, 5, 10, 25, 50]\n",
    "models = []\n",
    "for param in param_grid:\n",
    "    models.append(DecisionTreeClassifier(max_depth = param).fit(X=X_train, y=y_train))\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(model.score(X_val, y_val))\n",
    "\n",
    "# Saves results\n",
    "best_score = scores[scores.index(max(scores))]\n",
    "best_param = param_grid[scores.index(max(scores))]\n",
    "best_model = models[scores.index(max(scores))]\n",
    "\n",
    "# Performs Decision Tree Classifier\n",
    "model = DecisionTreeClassifier().fit(X=X_train, y=y_train)\n",
    "\n",
    "# Measures accuracy\n",
    "print(\"Best Parameter:\", best_param)\n",
    "dt_accuracy_train = best_model.score(X_train, y_train)\n",
    "dt_accuracy_val = best_score\n",
    "dt_accuracy_test = best_model.score(X_test, y_test)\n",
    "dt_scores = [dt_accuracy_train, dt_accuracy_val, dt_accuracy_test]\n",
    "print(\"Prediction accuracy on the train data:\", f\"{dt_accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{dt_accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Layer(torch.nn.Module):\n",
    "    def __init__(self, inputDim, outputDim, activation):\n",
    "        \n",
    "        super(Layer, self).__init__()\n",
    "        self.inputDim = inputDim\n",
    "        self.outputDim = outputDim\n",
    "        self.linear = torch.nn.Linear(inputDim, outputDim)\n",
    "        activation_functions = [torch.nn.Identity, torch.nn.ReLU, torch.nn.Tanh, torch.nn.Sigmoid]\n",
    "        activation_inputs = [\"Identity\", \"ReLU\", \"Tanh\", \"Sigmoid\"]\n",
    "        self.activation = activation_functions[activation_inputs.index(activation)]()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inp = self.linear(x)\n",
    "        output = self.activation(inp)\n",
    "        \n",
    "        return output\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        self.layers = layers\n",
    "        lst = []\n",
    "        for layer in layers:\n",
    "            lst += list(layer.parameters())\n",
    "        self.params = torch.nn.ParameterList(lst)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        temp_input = x\n",
    "        for layer in self.layers:\n",
    "            temp_input = layer.forward(temp_input)\n",
    "        return temp_input\n",
    "    def predict(self, data):\n",
    "        data_tensor = torch.FloatTensor(data)\n",
    "        return [torch.argmax(self.forward(item)).item() for item in data_tensor]\n",
    "    def score(self, x_test, y_test):\n",
    "        x_test_tensor = torch.FloatTensor(pd.DataFrame(x_test).values)\n",
    "        test_results = self.forward(x_test_tensor)\n",
    "        results = [torch.argmax(res).item() for res in test_results]\n",
    "        \n",
    "        total = 0\n",
    "        for i in range(len(results)):\n",
    "            if results[i] == y_test[i]:\n",
    "                total += 1\n",
    "\n",
    "        return total/len(y_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_construct(layer_dims, activation):\n",
    "    \n",
    "    return Neural_Network([Layer(layer_dims[i-1], layer_dims[i], activation) for i in range(1, len(layer_dims))])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def nn_trainer(model, X_train, y_train):\n",
    "    # Trains a model\n",
    "    # Input: model: the neural network to be trained (Neural_Network)\n",
    "    #        X_train: training for features\n",
    "    #        y_train: training data for target\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = torch.optim.Adam(model.params, lr=learning_rate)\n",
    "\n",
    "    for t in range(5000):\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        x_train_tensor = torch.FloatTensor(X_train)\n",
    "        \n",
    "        y_pred = model.forward(x_train_tensor)\n",
    "        \n",
    "        # Compute and print loss.\n",
    "        loss = criterion(y_pred, torch.tensor(pd.DataFrame(y_train).values, dtype = torch.long).reshape(-1))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.parameters(), model.forward(x_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs neural networks\n",
    "relu_model = nn_construct([96, 48, 4], \"ReLU\")\n",
    "sigmoid_model = nn_construct([96, 48, 4], \"Sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains neural networks\n",
    "relu_params, relu_activations = nn_trainer(relu_model, X_train.values, y_train)\n",
    "sigmoid_params, sigmoid_activations = nn_trainer(sigmoid_model, X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves results\n",
    "relu_test_score = relu_model.score(X_test,y_test)\n",
    "sigmoid_test_score = sigmoid_model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves results\n",
    "relu_train_score = relu_model.score(X_train, y_train)\n",
    "sigmoid_train_score = sigmoid_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves results\n",
    "relu_val_score = relu_model.score(X_val, y_val)\n",
    "sigmoid_val_score = sigmoid_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves results\n",
    "relu_scores = [relu_train_score, relu_val_score, relu_test_score]\n",
    "sigmoid_scores = [sigmoid_train_score, sigmoid_val_score, sigmoid_test_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a table for classification results\n",
    "summary = pd.DataFrame(data = {\"RBF Kernel SVM\": kernel_scores, \"Linear SVM\":linear_scores, \"Descision Tree\": dt_scores, \"Neural Network (ReLU Activation)\": relu_scores, \"Neural Network (Sigmoid Activation)\": sigmoid_scores})\n",
    "summary.index = [\"Accuracy on training\", \"Accuracy on validation\", \"Accuracy on testing\"]\n",
    "summary.T.to_html(\"tables/classification.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bita821192d7e144cac81722f01973f0984",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}