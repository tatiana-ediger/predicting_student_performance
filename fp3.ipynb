{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bita821192d7e144cac81722f01973f0984",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads data\n",
    "features = pd.read_csv(\"data/features.csv\")\n",
    "target = pd.read_csv(\"data/target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins target values\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=4, encode = \"onehot-dense\", strategy = \"quantile\")\n",
    "\n",
    "target_discretized = discretizer.fit_transform(target[\"G3\"].values.reshape(-1, 1))\n",
    "target_new = []\n",
    "for row in target_discretized:\n",
    "    target_new.append(list(row).index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into training, testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets final grade for target\n",
    "t_train = y_train[\"G3\"]\n",
    "t_test = y_test[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "R-squared value for training set:  0.34042660318538653\nR-squared value for testing set:  0.2277177794229266\n"
    }
   ],
   "source": [
    "# Imports Ridge and accuracy metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Performs Ridge Regression\n",
    "model = Ridge().fit(X=X_train, y=t_train)\n",
    "\n",
    "# Measures accuracy\n",
    "print(\"R-squared value for training set: \", r2_score(t_train, model.predict(X_train)))\n",
    "print(\"R-squared value for testing set: \", r2_score(t_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data for classification into training, testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_new, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction accuracy on the train data: 37.42%\nPrediction accuracy on the test data: 33.72%\n"
    }
   ],
   "source": [
    "# Imports SVC and accuracy metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Recommended using kernel\n",
    "\n",
    "# Performs SVC\n",
    "model = SVC(gamma = \"scale\").fit(X=X_train, y=y_train)\n",
    "\n",
    "# Measures accuracy\n",
    "accuracy_train = model.score(X_train, y_train)\n",
    "accuracy_test = model.score(X_test, y_test)\n",
    "print(\"Prediction accuracy on the train data:\", f\"{accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction accuracy on the train data: 100.00%\nPrediction accuracy on the test data: 38.31%\n"
    }
   ],
   "source": [
    "# Imports Decision Tree and accuracy metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Performs Decision Tree Classifier\n",
    "model = DecisionTreeClassifier().fit(X=X_train, y=y_train)\n",
    "\n",
    "# Recommended using kernel -> we want to be able to model nonlinear things!\n",
    "# Want to use feature expansion to classify them\n",
    "# To choose the kernel: brute force/ try out a bunch of different ones (look at data and see if there's anything interesting you can pick up on, for example see if there's any 2 or more things that you can take the product of and it seems interesting)\n",
    "# kernel: considering n features at the same time\n",
    "\n",
    "# Measures accuracy\n",
    "accuracy_train = model.score(X_train, y_train)\n",
    "accuracy_test = model.score(X_test, y_test)\n",
    "print(\"Prediction accuracy on the train data:\", f\"{accuracy_train:.2%}\")\n",
    "print(\"Prediction accuracy on the test data:\", f\"{accuracy_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, inputDim, outputDim, layerDim):\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.inputDim = inputDim\n",
    "        self.outputDim = outputDim\n",
    "        self.layerDim = layerDim\n",
    "\n",
    "\n",
    "        self.l1 = torch.nn.Linear(self.inputDim, self.layerDim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(self.layerDim, self.outputDim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.l1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.l2(relu)\n",
    "        # output = self.relu(output)\n",
    "        return output\n",
    "\n",
    "    def score(self, x_test, y_test):\n",
    "        x_test_tensor = torch.FloatTensor(X_test.values)\n",
    "        test_results = model.forward(x_test_tensor)\n",
    "        results = [torch.argmax(res).item() for res in test_results]\n",
    "        \n",
    "        total = 0\n",
    "        for i in range(len(results)):\n",
    "            if results[i] == y_test[i]:\n",
    "                total += 1\n",
    "\n",
    "        return total/len(y_test)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(96, 4, 48)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "99 1.5904982089996338\n199 1.353495717048645\n299 1.2996772527694702\n399 1.275328516960144\n499 1.2552828788757324\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Now have to loop through all my data points to optimize my model - for loop looping through groups of (5) data points at a time using indexing\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#loss = criterion(y_pred, torch.tensor(np.array(y_train).reshape(-1)))\n",
    "\n",
    "# model.eval()\n",
    "# x_test_tensor = torch.FloatTensor(X_test.iloc[3].values[1:])\n",
    "# y_pred = model(x_test_tensor)\n",
    "# before_train = criterion(y_pred.squeeze(), torch.FloatTensor(t_test.values[0]))\n",
    "# print('Test loss before training' , before_train.item())\n",
    "\n",
    "# training mode vs. evaluation mode\n",
    "# different architecture @ training/eval times\n",
    "# model.train()\n",
    "# y_pred = model(torch.FloatTensor(X_train.iloc[3].values[1:]))\n",
    "# y_pred\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# 2 inputs, first is model.parameters() - includes all parameters in the model you want to optimize, make sure model.parameters() includes everything you want to optimize\n",
    "\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    x_train_tensor = torch.FloatTensor(X_train.values)\n",
    "    y_pred = model(x_train_tensor)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = criterion(y_pred, torch.tensor(pd.DataFrame(y_train).values).reshape(-1))\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tensor = torch.FloatTensor(X_test.values)\n",
    "test_results = model.forward(x_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.10600255427841634"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "results = [torch.argmax(res).item() for res in test_results]\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ -1.0928,  -3.3668,  -8.8386, -17.7452, -23.2715,  -3.1942,  -2.3790,\n         -1.6477,  -0.6047,  -0.6456,   0.1171,  -0.0592,   0.0371,  -0.0275,\n         -0.5069,  -0.4071,  -0.8462,  -1.0783,  -1.3931,  -3.1473],\n       grad_fn=<SelectBackward>)"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "model.forward(x_test_tensor)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "848     8\n529    12\n348    15\n805    17\n45      6\n       ..\n356    13\n936    11\n724    14\n962     0\n779    10\nName: G3, Length: 261, dtype: int64"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}